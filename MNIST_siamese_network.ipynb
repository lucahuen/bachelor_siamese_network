{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# preparing the dataset",
   "id": "3ee43abd1ad36a52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SiameseNetworkDataset(Dataset):\n",
    "    def __init__(self, mnist_dataset, transform=None):\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "        # Build a label-to-indices mapping for faster class-based sampling:\n",
    "        # Dict: {0: [1, 2, 40,...],\n",
    "        #        1: [13, 7, 5,...],\n",
    "        #        ...}\n",
    "        self.label_to_indices = {}\n",
    "        for idx, (_, label) in enumerate(mnist_dataset):\n",
    "            if label not in self.label_to_indices:\n",
    "                self.label_to_indices[label] = []\n",
    "            self.label_to_indices[label].append(idx)\n",
    "        # print out 10 examples of each class\n",
    "        # for label, indices in self.label_to_indices.items():\n",
    "        #     print(f\"Label {label}: {indices[:10]}\")\n",
    "        # print(\"\\n\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get the data tuple at given index\n",
    "        img0, label0 = self.mnist_dataset[index]\n",
    "\n",
    "        # bool making sure training distribution is about 50/50\n",
    "        # -> 50% of pairs are of the same class, the other 50% are of different classes\n",
    "        should_get_same_class = random.randint(0, 1)\n",
    "\n",
    "        if should_get_same_class:\n",
    "            # get a different image of the same class\n",
    "            same_class_indices = self.label_to_indices[label0]\n",
    "            ## todo: remove index from same_class indices and choose random one\n",
    "            # initialize img1_index as the given index\n",
    "            img1_index = index\n",
    "            while img1_index == index:  # until we have a different index inside the same class\n",
    "                img1_index = random.choice(same_class_indices)\n",
    "        else:\n",
    "            # get an image of a different class\n",
    "            different_label = label0\n",
    "            while different_label == label0:  # keep randomizing until img1 class is different\n",
    "                different_label = random.choice(list(self.label_to_indices.keys()))\n",
    "            img1_index = random.choice(\n",
    "                self.label_to_indices[different_label])  # get a random index, as we are in a different class anyway\n",
    "\n",
    "        # get the img tuple\n",
    "        img1, label1 = self.mnist_dataset[img1_index]\n",
    "\n",
    "        # Convert to grayscale (MNIST is already grayscale, but this ensures PIL.Image format)\n",
    "        # TODO: try without these\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "\n",
    "        # 0 = same label/class, 1 = different labels/classes\n",
    "        pair_label = torch.tensor([int(label0 != label1)], dtype=torch.float32)\n",
    "        return img0, img1, pair_label\n",
    "\n",
    "    def __len__(self):\n",
    "        # fake number so training goes faster\n",
    "        return 10000\n",
    "        # return len(self.mnist_dataset)"
   ],
   "id": "3dd0672085971f91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## instantiating the dataset",
   "id": "8130cd47d7ebc8ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.RandomRotation(10), # rotates the images\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "mnist_train = MNIST(root='./data', train=True, download=True)\n",
    "siamese_train_dataset = SiameseNetworkDataset(mnist_train, transform=transform)"
   ],
   "id": "68de83768631cd18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## helper functions: imshow(), evaluate_siamese_model()",
   "id": "f0e22786b1323ee4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def imshow(img, text=None):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(5, 5, text, style='italic', fontweight='bold',\n",
    "                 bbox={'facecolor': 'white', 'alpha': 0.7, 'pad': 10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ],
   "id": "53691f12b4474102",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def evaluate_siamese_model(model, dataset, num_pairs=10):\n",
    "    \"\"\"\n",
    "    Evaluate a Siamese network model by visualizing image pairs and their dissimilarity scores.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained Siamese network.\n",
    "        dataset (torch.utils.data.Dataset): Dataset returning image pairs and binary labels.\n",
    "        num_pairs (int): Number of image pairs to evaluate and visualize.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    for i, (img1, img2, pair_label) in enumerate(loader):\n",
    "        if i >= num_pairs:\n",
    "            break\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            output1, output2 = model(img1, img2)\n",
    "            distance = F.pairwise_distance(output1, output2).item()\n",
    "\n",
    "        # Properly detach, squeeze, and prepare for display\n",
    "        img1_cpu = img1.squeeze(0).cpu()\n",
    "        img2_cpu = img2.squeeze(0).cpu()\n",
    "        concatenated = make_grid([img1_cpu, img2_cpu], nrow=2)\n",
    "\n",
    "        label_text = \"Same\" if pair_label.item() == 0 else \"Different\"\n",
    "        imshow(concatenated, text=f\"dissimilarity: {distance:.2f} | ground truth: {label_text}\")\n",
    "\n"
   ],
   "id": "f099f2c58bf81dab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## creating a visual dataloader and printing an example batch",
   "id": "578476af76e0c19c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# create a DataLoader\n",
    "vis_dataloader = DataLoader(siamese_train_dataset,\n",
    "                            shuffle=True,\n",
    "                            batch_size=8)\n",
    "\n",
    "# get a batch\n",
    "img0_batch, img1_batch, label_batch = next(iter(vis_dataloader))\n",
    "\n",
    "# concatenate pairs vertically for visualization\n",
    "concatenated = torch.cat([torchvision.utils.make_grid(img0_batch),\n",
    "                          torchvision.utils.make_grid(img1_batch)], dim=1)\n",
    "\n",
    "# Show the batch with labels\n",
    "imshow(concatenated, text=\"Labels: \" + \" \".join(str(int(l.item())) for l in label_batch))\n",
    "print(\"Labels:\", label_batch.numpy().reshape(-1))"
   ],
   "id": "1336cca81b4a0dd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# building the actual model",
   "id": "6e774b1458eef2d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(input_shape, hidden_units, kernel_size=3, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, stride=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_units * 3 * 3, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, output_shape),  # Final embedding size\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn(x)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n"
   ],
   "id": "a4816e085a41b4ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# building the contrastive loss funciton",
   "id": "77114e2babf015dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # print(f\"output1: {output1}, output2: {output2}, label: {label}\")\n",
    "        # Euclidean distance\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)\n",
    "        loss_contrastive = torch.mean(\n",
    "            (1 - label) * torch.pow(euclidean_distance, 2) +\n",
    "            label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        )\n",
    "        return loss_contrastive\n"
   ],
   "id": "9579a685e28c8070",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "w# prepare for training",
   "id": "18c38679fb851134"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(siamese_train_dataset, shuffle=True, batch_size=32)\n",
    "\n",
    "net = SiameseNetwork(input_shape=1, hidden_units=64, output_shape=len(siamese_train_dataset.label_to_indices.keys()))\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0005)"
   ],
   "id": "5cd646f2a4ff00f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TRAINING LOOP",
   "id": "3d019254d9c56121"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## try to load model first",
   "id": "adef0b97e2c9f2c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# Create the models directory if it doesn't exist\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"MNIST_siamese_network.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# Try loading the model if it exists\n",
    "if MODEL_SAVE_PATH.exists():\n",
    "    loaded_net = SiameseNetwork(\n",
    "        input_shape=1,\n",
    "        hidden_units=64,\n",
    "        output_shape=len(siamese_train_dataset.label_to_indices.keys())\n",
    "    )\n",
    "    loaded_net.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "    print(\"Model loaded from disk.\")\n",
    "else:\n",
    "    loaded_net = None\n",
    "    print(\"Model file not found. Will proceed to training.\")\n"
   ],
   "id": "61d7b43a185121d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## train (if no model was loaded)",
   "id": "a6b087e9ac764144"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop with tqdm progress bar\n",
    "num_epochs = 20\n",
    "if not loaded_net:  # if we don't have a saved model\n",
    "    print(f\"No model loaded, beginning training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        for img0, img1, label in progress_bar:\n",
    "            net.train()\n",
    "            # forward pass\n",
    "            output1, output2 = net(img0, img1)\n",
    "            # calculate loss\n",
    "            loss = criterion(output1, output2, label)\n",
    "            # zero the optimizer\n",
    "            optimizer.zero_grad()\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # step the optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            avg_loss = running_loss / (progress_bar.n + 1)\n",
    "            progress_bar.set_postfix(avg_loss=f\"{avg_loss:.4f}\")\n",
    "else:\n",
    "    print(f\"Loaded model found, skipping training...\")"
   ],
   "id": "272ca16393009bb5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## saving the model",
   "id": "ef89ea32d295bb4e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Only save if we didn't load a pre-existing model\n",
    "if loaded_net is None:\n",
    "    print(f\"Saving model to {MODEL_SAVE_PATH}\")\n",
    "    torch.save(obj=net.state_dict(), f=MODEL_SAVE_PATH)\n",
    "else:\n",
    "    print(\"Model already loaded. Skipping save.\")"
   ],
   "id": "7953396a9d186587",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# eval visualization",
   "id": "ace9c2370d0f3a47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define transform and dataset\n",
    "mnist = MNIST(root='./data', train=False, download=True)\n",
    "siamese_test_dataset = SiameseNetworkDataset(mnist, transform)\n",
    "\n",
    "if loaded_net is not None:\n",
    "    print(f\"Making predictions using loaded model (loaded_net)\")\n",
    "    evaluate_siamese_model(loaded_net, siamese_test_dataset)\n",
    "else:\n",
    "    print(f\"Making predictions using trained model (net)\")\n",
    "    evaluate_siamese_model(net, siamese_test_dataset)"
   ],
   "id": "17fcd342b19293ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6f699a62ebc5cd0e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
